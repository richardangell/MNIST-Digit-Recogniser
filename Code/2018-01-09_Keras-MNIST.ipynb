{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Important Pixels\n",
    "In this notebook a simple feedforward network is built to recognise MNIST images, using Keras. <br> We then try to identify important pixels in the prediction for a given image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import MNIST data from TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start: 2018-01-10 17:53:17.144182\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 2s 38us/step - loss: 0.3620 - acc: 0.8997 - val_loss: 0.2237 - val_acc: 0.9364\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 2s 33us/step - loss: 0.2140 - acc: 0.9381 - val_loss: 0.1787 - val_acc: 0.9498\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 2s 33us/step - loss: 0.1777 - acc: 0.9496 - val_loss: 0.1620 - val_acc: 0.9524\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 2s 34us/step - loss: 0.1562 - acc: 0.9560 - val_loss: 0.1542 - val_acc: 0.9534\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 2s 33us/step - loss: 0.1396 - acc: 0.9598 - val_loss: 0.1464 - val_acc: 0.9582\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 2s 34us/step - loss: 0.1291 - acc: 0.9628 - val_loss: 0.1323 - val_acc: 0.9626\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 2s 33us/step - loss: 0.1175 - acc: 0.9672 - val_loss: 0.1369 - val_acc: 0.9622\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 2s 34us/step - loss: 0.1104 - acc: 0.9692 - val_loss: 0.1368 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 2s 34us/step - loss: 0.1038 - acc: 0.9706 - val_loss: 0.1338 - val_acc: 0.9636\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 2s 34us/step - loss: 0.0988 - acc: 0.9721 - val_loss: 0.1281 - val_acc: 0.9650\n",
      "training end: 2018-01-10 17:53:36.168709\n"
     ]
    }
   ],
   "source": [
    "print(\"training start:\", str(datetime.now()))\n",
    "model.fit(mnist.train.images, \n",
    "          mnist.train.labels, \n",
    "          epochs = 10, \n",
    "          batch_size = 32,\n",
    "          validation_data = (mnist.validation.images, mnist.validation.labels))\n",
    "print(\"training end:\", str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds = model.predict(mnist.train.images)\n",
    "train_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"dense_1\").get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"dense_1\").get_weights()[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"dense_2\").get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"dense_2\").get_weights()[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Find important pixels for the predicted value of a given image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose image to consider\n",
    "For the first row of training data, plot the image (7) and get the predictions from the model. <br> Predicted probability for class 7 = 93%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18194c5400>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1819147978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(1 - mnist.train.images[0,].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "label: 7.0\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.labels[row_number])\n",
    "print(\"label:\" , np.dot(mnist.train.labels[row_number], np.arange(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , 0.07, 0.  , 0.  , 0.  , 0.93, 0.  , 0.  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(train_preds[row_number], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mulitply inputs (pixel values) by layer 1 weights \n",
    "For the first image, get pixel value * weight for each node (32) in layer 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_inputs_coefs(inputs, coefs):\n",
    "    print(\"inputs shape:\", inputs.shape)\n",
    "    print(\"coefs shape:\", coefs.shape)\n",
    "    outputs = np.multiply(inputs, coefs)\n",
    "    print(\"outputs shape:\", outputs.shape)\n",
    "    return(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape: (784,)\n",
      "coefs shape: (32, 784)\n",
      "outputs shape: (32, 784)\n"
     ]
    }
   ],
   "source": [
    "input_x_coef1 = multiply_inputs_coefs(mnist.train.images[row_number,],\n",
    "                                      np.transpose(model.get_layer(\"dense_1\").get_weights()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get intermediate layer outputs\n",
    "These will be needed in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_name = 'activation_1'\n",
    "intermediate_layer_model = Model(inputs = model.input,\n",
    "                                 outputs = model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(mnist.train.images)\n",
    "intermediate_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiply layer 1 outputs by layer 2 weights\n",
    "Now multiply the outputs from the activation_1 layer with the weights from the second dense layer, for each node (10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_output[0,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape: (32,)\n",
      "coefs shape: (10, 32)\n",
      "outputs shape: (10, 32)\n"
     ]
    }
   ],
   "source": [
    "input_x_coef2 = multiply_inputs_coefs(intermediate_output[row_number,],\n",
    "                                      np.transpose(model.get_layer(\"dense_2\").get_weights()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-9.635512</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.511566</td>\n",
       "      <td>-3.863917</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.703749</td>\n",
       "      <td>0.816451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13.624946</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.292560</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.125093</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-2.262531</td>\n",
       "      <td>-5.013208</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.006290</td>\n",
       "      <td>-2.941774</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.408508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>4.882957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012448</td>\n",
       "      <td>0.862640</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.911152</td>\n",
       "      <td>-0.132131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.497805</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.021082</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-3.556261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.237114</td>\n",
       "      <td>-2.775565</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.348504</td>\n",
       "      <td>-1.321098</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>4.380715</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.196869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-5.216155</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-4.121832</td>\n",
       "      <td>1.026034</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089106</td>\n",
       "      <td>-1.577839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-10.415653</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.080127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.862185</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.045770</td>\n",
       "      <td>-3.529841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.664488</td>\n",
       "      <td>-0.236531</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.464464</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.068978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-4.459607</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.071114</td>\n",
       "      <td>0.025152</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389079</td>\n",
       "      <td>0.586401</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-16.067297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046557</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.681025</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.453883</td>\n",
       "      <td>1.308520</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.184131</td>\n",
       "      <td>0.509653</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>4.101708</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.250607</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.786911</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.835756</td>\n",
       "      <td>-0.390771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779648</td>\n",
       "      <td>0.160527</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.319237</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.278729</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-12.508745</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.881541</td>\n",
       "      <td>-0.212099</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.499492</td>\n",
       "      <td>-0.630725</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-6.891692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.034289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0          1    2         3         4    5    6    7    8    9  ...   \\\n",
       "0 -0.0  -9.635512 -0.0  0.511566 -3.863917 -0.0 -0.0  0.0 -0.0 -0.0 ...    \n",
       "1  0.0   2.125093 -0.0 -2.262531 -5.013208 -0.0 -0.0 -0.0  0.0  0.0 ...    \n",
       "2 -0.0   4.882957  0.0  0.012448  0.862640 -0.0 -0.0 -0.0 -0.0 -0.0 ...    \n",
       "3 -0.0  -3.556261  0.0 -0.237114 -2.775565 -0.0 -0.0 -0.0 -0.0 -0.0 ...    \n",
       "4 -0.0  -5.216155 -0.0 -4.121832  1.026034 -0.0 -0.0 -0.0 -0.0 -0.0 ...    \n",
       "5  0.0  -2.862185 -0.0 -0.045770 -3.529841  0.0  0.0  0.0 -0.0  0.0 ...    \n",
       "6 -0.0  -4.459607 -0.0 -1.071114  0.025152 -0.0 -0.0  0.0  0.0 -0.0 ...    \n",
       "7 -0.0   0.681025 -0.0  0.453883  1.308520 -0.0 -0.0 -0.0 -0.0  0.0 ...    \n",
       "8 -0.0  -0.786911 -0.0 -0.835756 -0.390771  0.0 -0.0 -0.0 -0.0 -0.0 ...    \n",
       "9 -0.0 -12.508745 -0.0 -0.881541 -0.212099 -0.0 -0.0  0.0 -0.0 -0.0 ...    \n",
       "\n",
       "         22        23   24   25         26   27        28   29   30   31  \n",
       "0 -2.703749  0.816451  0.0  0.0 -13.624946 -0.0 -0.292560 -0.0 -0.0 -0.0  \n",
       "1 -3.006290 -2.941774 -0.0  0.0   0.091975  0.0 -0.408508  0.0  0.0  0.0  \n",
       "2 -1.911152 -0.132131  0.0  0.0   1.497805 -0.0 -0.021082 -0.0  0.0  0.0  \n",
       "3  1.348504 -1.321098 -0.0 -0.0   4.380715 -0.0 -0.196869  0.0 -0.0 -0.0  \n",
       "4 -0.089106 -1.577839  0.0 -0.0 -10.415653 -0.0  0.080127  0.0 -0.0 -0.0  \n",
       "5 -0.664488 -0.236531 -0.0 -0.0   1.464464 -0.0  0.068978  0.0 -0.0 -0.0  \n",
       "6  0.389079  0.586401 -0.0  0.0 -16.067297  0.0  0.046557 -0.0 -0.0 -0.0  \n",
       "7 -1.184131  0.509653 -0.0 -0.0   4.101708 -0.0 -0.250607 -0.0 -0.0 -0.0  \n",
       "8  0.779648  0.160527 -0.0  0.0  -2.319237 -0.0 -0.278729 -0.0  0.0  0.0  \n",
       "9 -2.499492 -0.630725 -0.0 -0.0  -6.891692  0.0 -0.034289  0.0  0.0 -0.0  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 20)\n",
    "pd.DataFrame(input_x_coef2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum inputs * weights by input for second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0000000e+00, -3.1336302e+01,  0.0000000e+00, -8.4777632e+00,\n",
       "       -1.2563054e+01,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -4.1109138e+01,\n",
       "       -4.4498386e+00,  0.0000000e+00, -3.4090316e+00, -9.0752649e+00,\n",
       "       -8.7471256e+00, -4.7755437e-03,  0.0000000e+00, -1.4600018e+01,\n",
       "       -1.5514387e+01, -5.5626068e+00, -9.5411777e+00, -4.7670665e+00,\n",
       "        0.0000000e+00,  0.0000000e+00, -3.7782158e+01,  0.0000000e+00,\n",
       "       -1.2869811e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2_sum_input = np.sum(input_x_coef2, axis = 0)\n",
    "layer2_sum_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiply weights through network\n",
    "value for pixel 1 = <br> input.weight(input1, node1) \\* \\[sum(input.weight(input1, node1), .., input.weight(input1, node10))\\] + <br>\n",
    "input.weight(input1, node2) \\* \\[sum(input.weight(input2, node1), .., input.weight(input2, node10))\\] + <br>\n",
    "input.weight(input1, node3) \\* \\[sum(input.weight(input3, node1), .., input.weight(input3, node10))\\] + <br>\n",
    "... <br>\n",
    "input.weight(input1, node32) \\* \\[sum(input.weight(input32, node1), .., input.weight(input32, node10))\\] <br>\n",
    "Note, the inputs are nodes within the sum refer to second dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_weight_network_sum = np.dot(layer2_sum_input, input_x_coef1)\n",
    "pixel_weight_network_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181a6b7d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Distribution of pixel input x weights through network')\n",
    "a = plt.hist(pixel_weight_network_sum, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x181a8b0080>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181a6ea240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pixel_weight_network_sum.reshape(28, 28), cmap='hot')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the product of input * weight through the network, starting at each pixel. <br>\n",
    "However given that the background for the images is white, these zero values propagate through the network, and hence we are just highlighting the non-background (zero) pixels. <br> Need to test this on a different dataset where the background is not all one colour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at softmax transformation\n",
    "First get output from second dense layer before going into the softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_name = 'dense_2'\n",
    "intermediate_layer_model = Model(inputs = model.input,\n",
    "                                 outputs = model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(mnist.train.images)\n",
    "intermediate_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-35.65, -28.33,  -5.15,  -1.95, -30.99, -18.99, -49.22,   0.62,\n",
       "       -17.73, -21.83], dtype=float32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(intermediate_output[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0) # only difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , 0.07, 0.  , 0.  , 0.  , 0.93, 0.  , 0.  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(softmax(intermediate_output[0]), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The large negative values output from the second dense layer are transformed to 0 through the softmax function. <br> This is a multiclass classification problem. <br> Negative \"network weights\" are mainly highlighted in the image. <br> Should just consider the path through the network from the pixel to the predicted class **which is not what is done above**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
